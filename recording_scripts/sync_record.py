import time
import ntplib
from datetime import datetime
import pyaudio
import wave


SAMPLES_TO_DISCARD = 44_100
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 44100
BYTES_PER_SAMPLE = 2


SECONDS_IN_MINUTE = 60
CHUNK = 1024 #Bytes per read 

#Method generated by DeepSeek
def get_ntp_offset(server='pool.ntp.org'):
    """Retrieve the offset between local time and NTP server time."""
    client = ntplib.NTPClient()
    try:
        response = client.request(server, version=3)
        return response.offset
    except (ntplib.NTPException, OSError) as e:
        print(f"Error querying NTP server: {e}")
        return 0.0  # Fallback to no offset


p = pyaudio.PyAudio() 
print("--------------------------------------------------------------")
devices = p.get_device_count()
for device in range(devices):
    device_info = p.get_device_info_by_index(device)
    #Check if this device is a microphone (an input device)
    if device_info.get('maxInputChannels') > 0:
      print(f"Microphone: {device_info.get('name')} , Device Index: {device_info.get('index')}")

recording_device = int(input("Please select a recording device: "))
print("--------------------------------------------------------------")

stream = p.open(format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                frames_per_buffer=CHUNK,
                input=True,
                input_device_index=recording_device)

minutes_to_record = int(input("Please enter amount of minutes to record: "))
location = input("Please enter recording location: ")
user_or_adversary_answer = input("User recording? (y/n): ")
match user_or_adversary_answer:
    case "y":
        user_or_adversary_answer = "USER"
    case _:
        user_or_adversary_answer = "ADVERSARY"

start_time_string = input("Please start time (hh:mm): ")
start_time = datetime.strptime(start_time_string, "%H:%M")
#Give the parsed time the correct date
offset_time = get_ntp_offset()

start_time = datetime.combine(datetime.today(), start_time.time())
print(f"waiting for:{(start_time-datetime.now()).total_seconds()-offset_time} seconds")
time.sleep((start_time-datetime.now()).total_seconds()-offset_time)
print(f"Starting to record for {minutes_to_record} minutes")
frames = []
for i in range(0,int(RATE/CHUNK * minutes_to_record * SECONDS_IN_MINUTE)):
    raw_audio_bytes = stream.read(CHUNK)
    frames.append(raw_audio_bytes)

stream.stop_stream()
stream.close()
p.terminate()
trimmed_audio_bytes = b''.join(frames)
trimmed_audio_bytes = trimmed_audio_bytes[SAMPLES_TO_DISCARD * BYTES_PER_SAMPLE:]
#Print file
file_path = f"{location}_{user_or_adversary_answer}_AUDIO_DATA"
with open(f"{file_path}.bin","wb") as file:
    file.write(trimmed_audio_bytes)
# Save to WAV file
wf = wave.open(f"{file_path}.wav", 'wb')
wf.setnchannels(CHANNELS)
wf.setsampwidth(p.get_sample_size(FORMAT))
wf.setframerate(RATE)
wf.writeframes(trimmed_audio_bytes)
wf.close()
print("Done!")
